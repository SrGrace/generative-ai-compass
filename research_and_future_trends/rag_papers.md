# Best RAG Papers

| Title | Summary | Tags | Timeline |
| --- | --- | --- | --- |
| [CRAG - Comprehensive RAG Benchmark](https://arxiv.org/pdf/2406.04744) | The Comprehensive RAG Benchmark (CRAG) addresses the limitations of existing RAG datasets by providing a diverse and dynamic set of 4,409 question-answer pairs and mock APIs for simulating web and Knowledge Graph searches. CRAG evaluates LLMs' QA capabilities across various domains and question categories, revealing that even state-of-the-art RAG solutions struggle with accuracy, especially on questions with higher dynamism, lower popularity, or higher complexity. The benchmark has already fostered significant engagement, paving the way for future research and improvements in RAG and general QA solutions. | RAG Evaluation | June 2024 |
| [Corrective Retrieval Augmented Generation](https://arxiv.org/pdf/2401.15884) | CRAG introduces a novel strategy to enhance the robustness and accuracy of large language models during retrieval-augmented generation processes. Addressing the potential pitfalls of relying on the relevance of retrieved documents, it employs a retrieval evaluator to gauge the quality and relevance of documents for a given query, enabling corrective retrieval strategies based on confidence scores. To overcome the limitations of static or outdated databases, CRAG integrates large-scale web searches, providing a richer pool of documents. Additionally, its unique knowledge refinement (decompose-filter-recompose) algorithm ensures the model focuses on pertinent information while discarding the irrelevant, thereby refining the quality of generation. Designed as a versatile, plug-and-play solution, CRAG significantly enhances RAG-based models' performance across a range of generation tasks, demonstrated through substantial improvements in four diverse datasets. | RAG Enhancement | Feb 2024 |
| [Searching for Best Practices in Retrieval-Augmented Generation](https://arxiv.org/pdf/2407.01219) | The paper explores the effectiveness of RAG techniques in providing up-to-date information, reducing hallucinations, and improving response quality, especially in specialized fields. Despite their benefits, RAG methods often face challenges with complexity and slow response times. Through comprehensive experiments, the authors propose strategies to optimize RAG practices, balancing performance and efficiency. Additionally, the study highlights how multimodal retrieval techniques can enhance question-answering for visual inputs and expedite multimodal content generation using a "retrieval as generation" approach. | RAG Best Practices | July 2024 |
| [RAG and Beyond]() | ğŸ”‘ Key Takeaways: <br><br> &nbsp; [ğŸ­] ğ—£ğ˜‚ğ—¿ğ—½ğ—¼ğ˜€ğ—² ğ—¼ğ—³ ğ—˜ğ˜…ğ˜ğ—²ğ—¿ğ—»ğ—®ğ—¹ ğ——ğ—®ğ˜ğ—® ğ—œğ—»ğ˜ğ—²ğ—´ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—»: Using external data enhances domain-specific expertise, temporal relevance, and reduces hallucination in LLMs, making outputs more controllable and interpretable.<br> &nbsp; [ğŸ®] ğ—™ğ—¼ğ˜‚ğ—¿ ğ—§ğ˜†ğ—½ğ—²ğ˜€ ğ—¼ğ—³ ğ—¤ğ˜‚ğ—²ğ—¿ğ˜† ğ—–ğ—¼ğ—ºğ—½ğ—¹ğ—²ğ˜…ğ—¶ğ˜ğ—¶ğ—²ğ˜€:<br> &nbsp; &nbsp; ğŸ”¸ ğ—Ÿğ—²ğ˜ƒğ—²ğ—¹ ğŸ­: ğ—˜ğ˜…ğ—½ğ—¹ğ—¶ğ—°ğ—¶ğ˜ ğ—™ğ—®ğ—°ğ˜ ğ—¤ğ˜‚ğ—²ğ—¿ğ—¶ğ—²ğ˜€: Direct fact retrieval from documents (e.g., â€œWho is the PM of India?â€).<br> &nbsp; &nbsp; ğŸ”¸ ğ—Ÿğ—²ğ˜ƒğ—²ğ—¹ ğŸ®: ğ—œğ—ºğ—½ğ—¹ğ—¶ğ—°ğ—¶ğ˜ ğ—™ğ—®ğ—°ğ˜ ğ—¤ğ˜‚ğ—²ğ—¿ğ—¶ğ—²ğ˜€: Requires basic reasoning or combining multiple pieces of data (e.g., â€œWho is the President of the country where New Delhi is located?â€).<br> &nbsp; &nbsp; ğŸ”¸ ğ—Ÿğ—²ğ˜ƒğ—²ğ—¹ ğŸ¯: ğ—œğ—»ğ˜ğ—²ğ—¿ğ—½ğ—¿ğ—²ğ˜ğ—®ğ—¯ğ—¹ğ—² ğ—¥ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¹ğ—² ğ—¤ğ˜‚ğ—²ğ—¿ğ—¶ğ—²ğ˜€: Needs domain-specific logic or rules from manuals (e.g., applying FDA guidelines for drug approval).<br> &nbsp; &nbsp; ğŸ”¸ ğ—Ÿğ—²ğ˜ƒğ—²ğ—¹ ğŸ°: ğ—›ğ—¶ğ—±ğ—±ğ—²ğ—» ğ—¥ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¹ğ—² ğ—¤ğ˜‚ğ—²ğ—¿ğ—¶ğ—²ğ˜€: Involves deeper, implicit patterns not explicitly stated, such as inferring economic impacts.<br> &nbsp; [ğŸ¯] ğ—§ğ—²ğ—°ğ—µğ—»ğ—¶ğ—¾ğ˜‚ğ—²ğ˜€ ğ—³ğ—¼ğ—¿ ğ—˜ğ˜…ğ˜ğ—²ğ—¿ğ—»ğ—®ğ—¹ ğ——ğ—®ğ˜ğ—® ğ—œğ—»ğ˜ğ—²ğ—´ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—»:<br> &nbsp; &nbsp; ğŸ”¸ ğ—–ğ—¼ğ—»ğ˜ğ—²ğ˜…ğ˜-ğ—¯ğ—®ğ˜€ğ—²ğ—± ğ—œğ—»ğ˜ğ—²ğ—´ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—»: Injecting relevant external data as context for better grounding.<br> &nbsp; &nbsp; ğŸ”¸ ğ—¦ğ—ºğ—®ğ—¹ğ—¹ ğ— ğ—¼ğ—±ğ—²ğ—¹ ğ—”ğ˜€ğ˜€ğ—¶ğ˜€ğ˜ğ—®ğ—»ğ—°ğ—²: Use of smaller models trained on specific data to guide the LLMâ€™s reasoning.<br> &nbsp; &nbsp; ğŸ”¸ ğ—™ğ—¶ğ—»ğ—²-ğ—§ğ˜‚ğ—»ğ—¶ğ—»ğ—´: Directly modifying LLM weights to adapt to specialized fields.<br> &nbsp; [ğŸ°] ğ—–ğ—µğ—®ğ—¹ğ—¹ğ—²ğ—»ğ—´ğ—²ğ˜€ ğ—¶ğ—» ğ—¥ğ—²ğ—®ğ—¹-ğ—ªğ—¼ğ—¿ğ—¹ğ—± ğ—¦ğ—°ğ—²ğ—»ğ—®ğ—¿ğ—¶ğ—¼ğ˜€:<br> &nbsp; &nbsp; ğŸ”¸ ğ—˜ğ—³ğ—³ğ—¶ğ—°ğ—¶ğ—²ğ—»ğ˜ ğ——ğ—®ğ˜ğ—® ğ—¥ğ—²ğ˜ğ—¿ğ—¶ğ—²ğ˜ƒğ—®ğ—¹: Finding the right external data with precision.<br> &nbsp; &nbsp; ğŸ”¸ ğ—œğ—»ğ˜ğ—²ğ—¿ğ—½ğ—¿ğ—²ğ˜ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜† & ğ—–ğ—¼ğ—»ğ˜ğ—¿ğ—¼ğ—¹ğ—¹ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜†: Making the modelâ€™s decision-making transparent, especially in fields like healthcare and finance.<br> &nbsp; &nbsp; ğŸ”¸ ğ—§ğ—®ğ˜€ğ—¸ ğ—–ğ—¼ğ—ºğ—½ğ—¹ğ—²ğ˜…ğ—¶ğ˜ğ˜† ğ— ğ—®ğ—»ğ—®ğ—´ğ—²ğ—ºğ—²ğ—»ğ˜: Understanding when a task requires multiple capabilities to be disentangled for better results.<br> &nbsp; [ğŸ±] ğ—¦ğ—¼ğ—¹ğ˜‚ğ˜ğ—¶ğ—¼ğ—»ğ˜€:<br> &nbsp; &nbsp; ğŸ”¸ ğ—¥ğ—”ğ—š ğ—™ğ—¿ğ—®ğ—ºğ—²ğ˜„ğ—¼ğ—¿ğ—¸ğ˜€: Combining retrieval and generation, with techniques like iterative RAG and graph/tree-based methods.<br> &nbsp; &nbsp; ğŸ”¸ ğ—£ğ—¿ğ—¼ğ—ºğ—½ğ˜ ğ—˜ğ—»ğ—´ğ—¶ğ—»ğ—²ğ—²ğ—¿ğ—¶ğ—»ğ—´ - ğ—–ğ—¼ğ—§, ğ—§ğ—¼ğ—§, ğ—Ÿğ—¼ğ—§ ğ—²ğ˜ğ—°.: Enhancing LLM interpretability using structured reasoning paths.<br> &nbsp; &nbsp; ğŸ”¸ ğ—™ğ—¶ğ—»ğ—²-ğ—§ğ˜‚ğ—»ğ—¶ğ—»ğ—´ ğ˜„ğ—¶ğ˜ğ—µ ğ—¥ğ—²ğ—±ğ˜‚ğ—°ğ—²ğ—± ğ—–ğ—¼ğ˜€ğ˜ğ˜€: Using adapter tuning, LoRA etc. to minimize the cost of domain-specific fine-tuning. | Survey | Sept 2024 |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |
