# Best Gen AI Papers of the month - weekly updates (November 2024)

## Week 1/4
| Title | Summary | Topics |
| --- | --- | --- |
| [Distinguishing Ignorance from Error in LLM Hallucinations](https://arxiv.org/pdf/2410.22071) | ğŸ” The Challenge: Ignorance vs. Error - This recent study introduces the concept of two hallucination types: <br> &nbsp; ğŸš« Lack of Knowledge (HK-): When the model simply doesn't know the answer <br> &nbsp; âš ï¸ Despite Knowledge (HK+): When the model gives wrong answers despite knowing the correct information! <br> <br> This distinction is critical, as each type requires different interventions. For HK-, external information is necessary, while HK+ errors can potentially be corrected by adjusting the model's internal logic. ğŸ§  <br> <br>Researchers also introduced WACK (Wrong Answers despite having Correct Knowledge), a novel approach to create model-specific datasets that help distinguish between these types of hallucinations. ğŸ¯ <br> <br>ğŸ”‘ Key findings:  <br> &nbsp; âœ¨ Different AI models have unique "knowledge fingerprints" and hallucination patterns  <br> &nbsp; ğŸ“ Model-specific datasets outperform generic ones in detecting hallucinations  <br> &nbsp; ğŸ”® It's possible to predict potential hallucinations BEFORE they happen! | Hallucinations |
| [Nearest Neighbor Normalization Improves Multimodal Retrieval](https://arxiv.org/pdf/2410.24114) | This new paper proposes an ingenious solution called Nearest Neighbor Normalization (NNN) - The key idea is to estimate and correct for bias in each retrieval candidate, using only the k nearest neighbours from a reference dataset.  <br> <br> ğŸ”‘ This simple yet effective technique provides a few key benefits: <br> &nbsp; âœ… Consistent improvements in retrieval accuracy across a range of state-of-the-art models and datasets ğŸ“ˆ <br> &nbsp; âœ… Significant reductions in gender bias for image retrieval ğŸŒ <br> &nbsp; âœ… Efficient implementation using vector search, making it practical for real-world use ğŸš€ <br> <br> The authors demonstrate NNN can match the performance of finetuning the models, but with no additional training required. Really clever stuff! ğŸ‘ | Multimodal Retrieval improvement |
| [Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation](https://arxiv.org/pdf/2411.00412) | This new research tackles one of AI's biggest challenges: knowing when to solve problems directly vs. when to use specialized tools - a skill that comes naturally to human experts! ğŸ§  <br> <br> ğŸ”‘ They propose a two-stage learning approach that: <br> &nbsp; ğŸ“š First teaches AI to internalize scientific knowledge (like we do in school) - World Knowledge Distillation (WKD) <br> &nbsp;  ğŸ¯ Then trains it to make smart decisions about using advanced tools (like experienced scientists do) - Tool Usage Adaptation (TUA) <br> <br> ğŸ“ˆ The results are incredible: <br> &nbsp;  ğŸ”¹ 28% jump in accuracy across complex scientific tasks <br> &nbsp;  ğŸ”¹ 14% better at deciding when tools are actually needed <br> &nbsp;  ğŸ”¹ Outperformed GPT-4 and Claude 3.5 on specialized scientific problems <br> &nbsp;  ğŸ”¹ All this from a smaller, more efficient model! ğŸ’ª <br> <br> ğŸŒ Real-world impact? Imagine AI research assistants that can: <br> &nbsp;  ğŸ§ª Know when to run complex simulations <br> &nbsp;  ğŸ“Š Decide when basic calculations are enough <br> &nbsp;  âš¡ Save computational resources <br> &nbsp;  ğŸ¯ Deliver more reliable results | Adapting while Learning |
| []() |  |  |
| []() |  |  |
| []() |  |  |



## Week 2/4
| Title | Summary | Topics |
| --- | --- | --- |
| []() |  |  |
| []() |  |  |


## Week 3/4
| Title | Summary | Topics |
| --- | --- | --- |
| []() |  |  |
| []() |  |  |


## Week 4/4
| Title | Summary | Topics |
| --- | --- | --- |
| []() |  |  |
| []() |  |  |
