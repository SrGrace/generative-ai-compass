# Best Gen AI Papers of the month - weekly updates (September 2024)

## Week 1/4
| Title | Summary | Topics |
| --- | --- | --- |
| [RAG in the Era of Long-Context LLMs](https://arxiv.org/pdf/2409.01666) | The paper revisits the use of Retrieval-Augmented Generation (RAG) for long-context answer generation, despite the emergence of long-context Large Language Models (LLMs) that can incorporate longer text sequences. The authors argue that extremely long contexts in LLMs can lead to a diminished focus on relevant information and decreased answer quality.<br><br> Key Contributions: <br> &nbsp; - Proposal of an Order-Preserve Retrieval-Augmented Generation (OP-RAG) mechanism that improves RAG performance for long-context question-answer applications. <br> &nbsp; - Discovery of an inverted U-shaped curve, where answer quality initially rises and then declines as the number of retrieved chunks increases. <br> &nbsp; - Identification of "sweet points" where OP-RAG achieves higher answer quality with fewer tokens than long-context LLMs. <br><br> Main Claim: <br> &nbsp; The paper claims that OP-RAG can outperform long-context LLMs in certain scenarios, making it a viable solution for long-context answer generation. | RAG for long-context answer generation |
| [Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation](https://arxiv.org/pdf/2409.03271v1) | The paper addresses the instability of Chain-of-Thought (CoT) methods in large language models (LLMs), which can lead to suboptimal reasoning performance. To overcome this, the authors propose the Strategic Chain-of-Thought (SCoT) methodology.<br><br> Key Contributions: <br> &nbsp; - SCoT integrates strategic knowledge to refine LLM performance by generating high-quality CoT paths and final answers.<br> &nbsp; - A two-stage approach is employed within a single prompt: eliciting an effective problem-solving strategy, followed by guided generation of CoT paths and final answers.<br> &nbsp; - Experimental results show significant improvements on eight challenging reasoning datasets, including a 21.05% increase on the GSM8K dataset and 24.13% on the Tracking Objects dataset.<br><br> Main Claim: <br> &nbsp; The paper claims that SCoT substantially enhances LLM performance in complex reasoning tasks, demonstrating its potential as a novel methodology for improving CoT methods. | Chain-of-Thought |
| [Large Language Model-Based Agents for Software Engineering: A Survey](https://arxiv.org/pdf/2409.02977) | The paper presents a comprehensive survey on Large Language Model (LLM)-based agents in the context of Software Engineering (SE). <br><br> Key Contributions: <br> &nbsp; - The survey collects and categorizes 106 papers on LLM-based agents for SE from two perspectives: SE and agent perspectives. <br> &nbsp; - The paper discusses the effectiveness of LLM-based agents in SE and their potential in tackling complex real-world problems through synergy with multiple agents and human interaction. <br> &nbsp; - The survey highlights open challenges and future directions in this critical domain. <br><br> Main Claim: <br> &nbsp; The paper aims to provide a systematic understanding of the current state of LLM-based agents in SE, identifying areas of promise and challenges for future research. <br><br> Additional Resource: <br> &nbsp; The survey's repository is available at https://github.com/FudanSELab/Agent4SE-Paper-List. | LLM Agents |
| [OLMoE: Open Mixture-of-Experts Language Models](https://arxiv.org/pdf/2409.02060) | The paper introduces OLMOE, a state-of-the-art language model that leverages sparse Mixture-of-Experts (MoE) architecture.<br><br> Key Contributions: <br> &nbsp; - OLMOE-1B-7B has 7 billion parameters but uses only 1 billion per input token, making it efficient. <br> &nbsp; - The model is pretrained on 5 trillion tokens and further adapted to create OLMOE-1B-7B-INSTRUCT. <br> &nbsp; - OLMOE outperforms other models with similar active parameters, including larger ones like Llama2-13B-Chat and DeepSeekMoE-16B.<br><br> Main Claim: <br> &nbsp; The paper claims that OLMOE is a highly efficient and effective language model that achieves state-of-the-art results while being fully open-sourced.  <br><br> Open-Source Resources: <br> &nbsp; - Model weights: https://hf.co/allenai/OLMoE-1B-7B-0924 <br> &nbsp; - Training data: https://hf.co/datasets/allenai/OLMoE-mix-0924 <br> &nbsp; - Code: https://github.com/allenai/OLMoE <br> &nbsp; - Logs: https://wandb.ai/ai2-llm/olmoe/reports/| Mixture-of-Experts Language Models |
| [Beyond Preferences in AI Alignment](https://arxiv.org/pdf/2408.16984) | The paper challenges the dominant practice of AI alignment, which assumes that human preferences are an adequate representation of human values and that AI systems should be aligned with these preferences. The authors argue that this "preferentist approach" has limitations and propose alternative conceptual and technical frameworks for AI alignment.<br><br> Key Points: <br> &nbsp; - The paper critiques the use of rational choice theory and expected utility theory (EUT) as a basis for AI alignment, arguing that they fail to capture the complexity of human values and neglect the possibility of incommensurable values. <br> &nbsp; - The authors propose a reframing of AI alignment, where AI systems are aligned with normative standards appropriate to their social roles, rather than with human preferences. <br> &nbsp; - This alternative approach emphasizes the importance of negotiating and agreeing upon normative standards with all relevant stakeholders, allowing for a multiplicity of AI systems to serve diverse ends while promoting mutual benefit and limiting harm.<br><br> Main Claim: <br> &nbsp; The paper argues that the preferentist approach to AI alignment is inadequate and that a new framework is needed to ensure that AI systems are aligned with human values and promote beneficial outcomes. | Beyond Preference in AI Alignment  |
|  |  |  |


## Week 2/4
| Title | Summary | Topics |
| --- | --- | --- |
| [Learning to Reason with LLMs](https://openai.com/index/learning-to-reason-with-llms/) | OpenAI o1â€”a new series of AI models designed to spend more time thinking before they respond. These models can reason through complex tasks and solve harder problems than previous models in science, coding, and math. o1 ranks in the 89th percentile on competitive programming questions, places among the top 500 students in the US in a qualifier for the USA Math Olympiad, and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems. | Large Language Models |
| [Chai-1: Decoding the molecular interactions of life](https://www.chaidiscovery.com/blog/introducing-chai-1) | A new multi-modal foundation model for molecular structure prediction that performs at the state-of-the-art across a variety of tasks relevant to drug discovery. Chai-1 enables unified prediction of proteins, small molecules, DNA, RNA, covalent modifications, and more. <br><br> Ope-Source Resources: <br> &nbsp; - Github: https://github.com/chaidiscovery/chai-lab <br> &nbsp; - Try yourself: http://lab.chaidiscovery.com/ | Multi-Modal Foundation Model |
| [Can LLMs Generate Novel Research Ideas?](https://arxiv.org/pdf/2409.04109) | This study evaluates the ability of large language models (LLMs) to generate novel, expert-level research ideas. The experiment compared ideas generated by LLMs with those produced by over 100 NLP researchers. The results showed that:  <br> &nbsp; - LLM-generated ideas were judged as more novel (p < 0.05) than human expert ideas. <br> &nbsp; - LLM-generated ideas were slightly weaker on feasibility.  <br><br>However, the study also identified open problems in building and evaluating research agents, including: <br> &nbsp; - LLM self-evaluation failures <br> &nbsp; - Lack of diversity in generation  <br><br> The authors propose a follow-up study to execute the generated ideas into full projects, enabling the evaluation of whether novelty and feasibility judgements result in meaningful differences in research outcomes. <br><br>Related GitHub Repository: https://github.com/NoviScl/AI-Researcher | LLMs on Research |
| [Agent Memory Workflow (AWM)](https://arxiv.org/pdf/2409.07429) | Current language-based agents struggle with long-horizon tasks and lack the ability to learn reusable task workflows from past experiences. <br><br>This paper aims to introduce "Agent Memory Workflow (AWM)", a method that can induce commonly reused task routines, called "workflows", and selectively provide them to agents to guide their future actions. This can help language model-based agents solve complex real-world tasks, such as web navigation. <br><br> Methodology: The authors propose two ways to implement AWM: <br> &nbsp; 1. Offline AWM: Workflows are induced from available training examples and integrated into the agent's memory before solving test tasks.<br> &nbsp; 2. Online AWM: Workflows are induced from the agent's own predictions on test tasks and continuously added to the agent's memory during inference. <br><br>Results and findings: This approach has shown significant improvements in web navigation tasks, covering 1000+ tasks from 200+ domains, with: <br> &nbsp; 1. 24.6% relative success rate increase on the Mind2Web benchmark <br> &nbsp; 2. 51.1% relative success rate increase on the WebArena benchmark <br><br>AWM also demonstrates strong generalization abilities, outperforming baselines by 8.9-14.0 absolute points on cross-website and cross-domain evaluations. | Agents |
| [DataGemma: Using real-world data to address AI hallucinations](https://docs.datacommons.org/papers/DataGemma-FullPaper.pdf) | DataGemma, a new set of open models that combines the strengths of Large Language Models (LLMs) with the real-world statistical data from Data Commons. This approach enables users to ask natural language questions and receive accurate answers, backed by verifiable data sources, addressing AI Hallucinations. <br><br> Key Points: <br> &nbsp; - Hybrid approach: Combines LLMs with Data Commons (a knowledge graph containing over 240 billion data points from sources like the UN, WHO,, CDC and Census Bureaus) to provide accurate and reliable answers. <br> &nbsp; - the idea lies in its two distinct approaches:  <br> &nbsp; &nbsp; - Retrieval-Interleaved Generation (RIG): Proactively queries Data Commons during response generation to assess response accuracy, and  <br> &nbsp; &nbsp; - Retrieval-Augmented Generation (RAG): Retrieves relevant context for generating response <br><br> Training and Architecture: <br> &nbsp; - Training: It is built on Google's Gemma architecture and trained on TPUv5e using JAX on synthetically generated data by Gemini 1.5. <br> &nbsp; - Data Commons Integration: Utilises Data Commons' vast resources to fetch relevant tables and data. <br> &nbsp; - RIG Evaluation Tool: Employs a two-stage evaluation process to assess response accuracy.<br><br> Performance Benchmarks and Metrics: <br> &nbsp; - Factual Accuracy: Achieves 58% accuracy in factual accuracy metrics, outperforming baseline models. <br> &nbsp; - Comparison to Baseline Models: Improves factuality from 5-17% to 58% in certain scenarios. <br> &nbsp; - Error Analysis: Identifies areas for improvement, including cases where both Data Commons and LLM responses are incorrect.<br><br> Limitations: <br> &nbsp; - Potential for Controversial Responses: May produce responses that are controversial, inflammatory or outdated since it relies primarily on one knowledge source - Data Commons. <br> &nbsp; - Performance concerns: The computational overhead and impact on inference time when using this two-stage solution in real-world application are of concern. | RAG and Hallucination |
| [LLaMA-Omni](https://arxiv.org/pdf/2409.06666) | Llama-Omni is a model architecture for low-latency speech interaction with LLMs.  <br><br> Key Points: <br> &nbsp; - Apparently, this is the open-source answer to GPT-4o real-time speech interaction and it is based on Llama-3.1-8B-Instruct.  <br> &nbsp; - Llama-Omni can simultaneously generate both text and speech responses given speech instructions.  <br> &nbsp; - Responses can be generated with a response latency as low as 226ms. <br> &nbsp; - Architecture-wise, it involves a speech encoder (Whisper-large-v3), a speech adaptor, an LLM, and a speech decoder. <br> &nbsp; - They also created InstructS2S-200K, a dataset of 200K speech instructions and responses, to align the model with speech interaction scenarios. <br> &nbsp; - training LLaMA-Omni takes less than 3 days on just 4 GPUs, paving the way for the efficient development of speech-language models in the future <br><br> Code and model: https://github.com/ictnlp/LLaMA-Omni | Speech interaction with LLMs |
|  |  |  |


## Week 3/4
| Title | Summary | Topics |
| --- | --- | --- |
| [Moshi: a speech-text foundation model for real-time dialogue](https://kyutai.org/Moshi.pdf) | The paper introduces Moshi: a speech-text foundation model and full-duplex spoken dialogue framework. <br> they present several components of the systems: <br> &nbsp; - Helium is a 7B parameter text LLM <br> &nbsp; -  Mimi is a semantic-acoustic neural audio code with state-of-the-art performance on audio quality  <br> &nbsp; - a hierarchical multi-stream architecture that can generate arbitrary conversation in a speech-to-speech manner. <br><br> &nbsp; - git repo: https://t.co/PFak47FMrm <br> &nbsp; - HuggingFace: https://t.co/bqG4IS0ntg| Speech-text Foundation model |
| [Training LLMs to Self-Correct via RL](https://arxiv.org/pdf/2409.12917) | This breakthrough uses reinforcement learning to enhance LLMs' self-correction abilities. Traditional fine-tuning falls short, so they developed a two-stage approach: first optimizing correction behaviour, then amplifying self-correction during training. Applied to Gemini models, it improved self-correction by up to 15.6% on benchmark tests! | LLMs |
| [Qwen2.5-Coder](https://arxiv.org/pdf/2409.12186) | A series of models including 1.5B and 7B parameters; itâ€™s built upon the Qwen2.5 architecture which is continuously pretrained on 5.5 trillion tokens; achieves state-of-the-art performance across more than 10 benchmarks; includes strong capabilities in code generation, completion, reasoning, and repairing. | Code Model |
| [On the Diagram of Thought](https://arxiv.org/pdf/2409.10038) | ğŸ”‘ Key Insights:  <br><br> &nbsp; ğŸ”¹ DoT models iterative reasoning as a directed acyclic graph (DAG) within a single LLM <br> &nbsp; ğŸ”¹ Enables exploration of complex reasoning pathways while maintaining logical consistency <br> &nbsp; ğŸ”¹ Organizes propositions, critiques, refinements, and verifications into a cohesive structure <br> &nbsp; ğŸ”¹ Leverages auto-regressive next-token prediction with role-specific tokens <br> &nbsp; ğŸ”¹ Formalizes the framework using Topos Theory for mathematical rigor - In case you're wondering like me ğŸ¤” ...Imagine you're building a complex Lego structure. Topos Theory is like a super-advanced set of Lego building rules that helps you construct and understand incredibly complex structures, not just with plastic bricks, but with ideas and logic. | AI Reasoning |
| [TO COT OR NOT TO COT?](https://arxiv.org/pdf/2409.12183) | This meta-analysis of over 100 papers reveals that Chain-of-Thought (CoT) prompting shines brightest in math and logic tasks. It significantly improves symbolic execution, but interestingly, dedicated symbolic solvers still have an edge. It's a reminder that even powerful techniques have their sweet spots! | Prompting |
| [Iteration of Thought](https://arxiv.org/pdf/2409.12618) | IoT introduces a dynamic framework that adapts reasoning paths on the fly. Unlike rigid processes, IoT uses an inner dialogue agent to guide and adjust reasoning. It's like giving AI the power of real-time self-reflection and course correction! | AI Reasoning |
| [Jailbreaking Large Language Models with Symbolic Mathematics](https://arxiv.org/pdf/2409.11445) | Researchers used GPT-4 to generate mathematically encoded prompts that bypass AI safety measures with a 73.6% success rate across 13 state-of-the-art models. It's a critical discovery highlighting the need for more robust safety mechanisms in AI. | Prompting |
|  |  |  |


## Week 4/4
| Title | Summary | Topics |
| --- | --- | --- |
| [SMALL LANGUAGE MODELS: SURVEY, MEASUREMENTS, AND INSIGHTS](https://arxiv.org/pdf/2409.15790) | ğŸ”‘ Key Highlights: <br><br> &nbsp; [1]. SLM Overview: Focusing on models with 100Mâ€“5B parameters, SLMs are designed to operate efficiently on devices like smartphones, IoT gadgets, and wearables, in contrast to large language models (LLMs) running in data centres.<br> &nbsp; [2]. Architectural Innovations: SLMs are shifting to use Group-Query Attention and Gated Feed Forward Networks (FFNs), replacing older multi-head attention mechanisms, significantly improving their on-device performance.<br> &nbsp; [3]. Benchmarking: Over 59 SLMs were evaluated across multiple dimensionsâ€”commonsense reasoning, in-context learning, mathematics, and codingâ€”showing SLMs are closing the gap with LLMs, especially in problem-solving and reasoning tasks.<br> &nbsp; [4]. On-device Performance: Analysis of inference latency and memory usage shows SLMs are optimized for on-device environments, significantly reducing memory footprint and latency.<br> &nbsp; [5]. Data Quality Over Quantity: Training on high-quality datasets like DCLM and FineWeb-Edu is critical to SLM performance. The recent trend in SLM research is filtering data with model-based methods to achieve better performance on less training data.<br> &nbsp; [6]. In-Context Learning: SLMs have shown strong improvements in in-context learning, with models like Gemma 2 showing a 4.8% accuracy increase through 5-shot learning on complex tasks.<br> &nbsp; [7]. Over-Training for Deployment: Contrary to Chinchilla Law (- In case you're wondering like me ğŸ¤”...This law basically suggests the optimal balance between model size and training data for maximum efficiency, reducing computational costs without sacrificing performance), many SLMs are "over-trained" on more tokens than predicted for their size, optimizing them for deployment on resource-constrained devices.<br> &nbsp; [8]. Collaborative AI: Future research suggests hybrid approaches where SLMs handle easier tasks locally, while cloud-based LLMs tackle more complex problems, improving device-cloud collaboration.<br><br>ğŸ’¡ Looking Ahead:<br> &nbsp; ğŸ”¹Co-design of SLM architectures and hardware is vital to further optimize performance.<br> &nbsp; ğŸ”¹Continual learning for personalization will enable SLMs to adapt to user preferences, while keeping data secure.<br> &nbsp; ğŸ”¹Sparse SLMs and their impact on device memory and computation are underexplored areas with great potential. | SLMs |
| [RAG and Beyond](https://arxiv.org/pdf/2409.14924v1) | ğŸ”‘ Key Takeaways: <br><br> &nbsp; [ğŸ­] ğ—£ğ˜‚ğ—¿ğ—½ğ—¼ğ˜€ğ—² ğ—¼ğ—³ ğ—˜ğ˜…ğ˜ğ—²ğ—¿ğ—»ğ—®ğ—¹ ğ——ğ—®ğ˜ğ—® ğ—œğ—»ğ˜ğ—²ğ—´ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—»: Using external data enhances domain-specific expertise, temporal relevance, and reduces hallucination in LLMs, making outputs more controllable and interpretable. <br> &nbsp; [ğŸ®] ğ—™ğ—¼ğ˜‚ğ—¿ ğ—§ğ˜†ğ—½ğ—²ğ˜€ ğ—¼ğ—³ ğ—¤ğ˜‚ğ—²ğ—¿ğ˜† ğ—–ğ—¼ğ—ºğ—½ğ—¹ğ—²ğ˜…ğ—¶ğ˜ğ—¶ğ—²ğ˜€: <br> &nbsp; &nbsp; ğŸ”¸ ğ—Ÿğ—²ğ˜ƒğ—²ğ—¹ ğŸ­: ğ—˜ğ˜…ğ—½ğ—¹ğ—¶ğ—°ğ—¶ğ˜ ğ—™ğ—®ğ—°ğ˜ ğ—¤ğ˜‚ğ—²ğ—¿ğ—¶ğ—²ğ˜€: Direct fact retrieval from documents (e.g., â€œWho is the PM of India?â€). <br> &nbsp; &nbsp;ğŸ”¸ ğ—Ÿğ—²ğ˜ƒğ—²ğ—¹ ğŸ®: ğ—œğ—ºğ—½ğ—¹ğ—¶ğ—°ğ—¶ğ˜ ğ—™ğ—®ğ—°ğ˜ ğ—¤ğ˜‚ğ—²ğ—¿ğ—¶ğ—²ğ˜€: Requires basic reasoning or combining multiple pieces of data (e.g., â€œWho is the President of the country where New Delhi is located?â€). <br> &nbsp; &nbsp;ğŸ”¸ ğ—Ÿğ—²ğ˜ƒğ—²ğ—¹ ğŸ¯: ğ—œğ—»ğ˜ğ—²ğ—¿ğ—½ğ—¿ğ—²ğ˜ğ—®ğ—¯ğ—¹ğ—² ğ—¥ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¹ğ—² ğ—¤ğ˜‚ğ—²ğ—¿ğ—¶ğ—²ğ˜€: Needs domain-specific logic or rules from manuals (e.g., applying FDA guidelines for drug approval). <br> &nbsp; &nbsp;ğŸ”¸ ğ—Ÿğ—²ğ˜ƒğ—²ğ—¹ ğŸ°: ğ—›ğ—¶ğ—±ğ—±ğ—²ğ—» ğ—¥ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¹ğ—² ğ—¤ğ˜‚ğ—²ğ—¿ğ—¶ğ—²ğ˜€: Involves deeper, implicit patterns not explicitly stated, such as inferring economic impacts. <br> &nbsp; [ğŸ¯] ğ—§ğ—²ğ—°ğ—µğ—»ğ—¶ğ—¾ğ˜‚ğ—²ğ˜€ ğ—³ğ—¼ğ—¿ ğ—˜ğ˜…ğ˜ğ—²ğ—¿ğ—»ğ—®ğ—¹ ğ——ğ—®ğ˜ğ—® ğ—œğ—»ğ˜ğ—²ğ—´ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—»: <br> &nbsp; &nbsp;ğŸ”¸ ğ—–ğ—¼ğ—»ğ˜ğ—²ğ˜…ğ˜-ğ—¯ğ—®ğ˜€ğ—²ğ—± ğ—œğ—»ğ˜ğ—²ğ—´ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—»: Injecting relevant external data as context for better grounding. <br> &nbsp; &nbsp;ğŸ”¸ ğ—¦ğ—ºğ—®ğ—¹ğ—¹ ğ— ğ—¼ğ—±ğ—²ğ—¹ ğ—”ğ˜€ğ˜€ğ—¶ğ˜€ğ˜ğ—®ğ—»ğ—°ğ—²: Use of smaller models trained on specific data to guide the LLMâ€™s reasoning. <br> &nbsp; &nbsp;ğŸ”¸ ğ—™ğ—¶ğ—»ğ—²-ğ—§ğ˜‚ğ—»ğ—¶ğ—»ğ—´: Directly modifying LLM weights to adapt to specialized fields. <br> &nbsp; [ğŸ°] ğ—–ğ—µğ—®ğ—¹ğ—¹ğ—²ğ—»ğ—´ğ—²ğ˜€ ğ—¶ğ—» ğ—¥ğ—²ğ—®ğ—¹-ğ—ªğ—¼ğ—¿ğ—¹ğ—± ğ—¦ğ—°ğ—²ğ—»ğ—®ğ—¿ğ—¶ğ—¼ğ˜€: <br> &nbsp; &nbsp;ğŸ”¸ ğ—˜ğ—³ğ—³ğ—¶ğ—°ğ—¶ğ—²ğ—»ğ˜ ğ——ğ—®ğ˜ğ—® ğ—¥ğ—²ğ˜ğ—¿ğ—¶ğ—²ğ˜ƒğ—®ğ—¹: Finding the right external data with precision. <br> &nbsp; &nbsp;ğŸ”¸ ğ—œğ—»ğ˜ğ—²ğ—¿ğ—½ğ—¿ğ—²ğ˜ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜† & ğ—–ğ—¼ğ—»ğ˜ğ—¿ğ—¼ğ—¹ğ—¹ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜†: Making the modelâ€™s decision-making transparent, especially in fields like healthcare and finance. <br> &nbsp; &nbsp;ğŸ”¸ ğ—§ğ—®ğ˜€ğ—¸ ğ—–ğ—¼ğ—ºğ—½ğ—¹ğ—²ğ˜…ğ—¶ğ˜ğ˜† ğ— ğ—®ğ—»ğ—®ğ—´ğ—²ğ—ºğ—²ğ—»ğ˜: Understanding when a task requires multiple capabilities to be disentangled for better results. <br> &nbsp; [ğŸ±] ğ—¦ğ—¼ğ—¹ğ˜‚ğ˜ğ—¶ğ—¼ğ—»ğ˜€: <br> &nbsp; &nbsp;ğŸ”¸ ğ—¥ğ—”ğ—š ğ—™ğ—¿ğ—®ğ—ºğ—²ğ˜„ğ—¼ğ—¿ğ—¸ğ˜€: Combining retrieval and generation, with techniques like iterative RAG and graph/tree-based methods. <br> &nbsp; &nbsp;ğŸ”¸ ğ—£ğ—¿ğ—¼ğ—ºğ—½ğ˜ ğ—˜ğ—»ğ—´ğ—¶ğ—»ğ—²ğ—²ğ—¿ğ—¶ğ—»ğ—´ - ğ—–ğ—¼ğ—§, ğ—§ğ—¼ğ—§, ğ—Ÿğ—¼ğ—§ ğ—²ğ˜ğ—°.: Enhancing LLM interpretability using structured reasoning paths. <br> &nbsp; &nbsp;ğŸ”¸ ğ—™ğ—¶ğ—»ğ—²-ğ—§ğ˜‚ğ—»ğ—¶ğ—»ğ—´ ğ˜„ğ—¶ğ˜ğ—µ ğ—¥ğ—²ğ—±ğ˜‚ğ—°ğ—²ğ—± ğ—–ğ—¼ğ˜€ğ˜ğ˜€: Using adapter tuning, LoRA etc. to minimize the cost of domain-specific fine-tuning.| RAG |
|  |  |  |
|  |  |  |
|  |  |  |
