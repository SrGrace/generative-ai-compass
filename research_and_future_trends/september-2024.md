# Best Gen AI Papers of the month - weekly updates (September 2024)

## Week 1/4
| Title | Summary | Topics |
| --- | --- | --- |
| [RAG in the Era of Long-Context LLMs](https://arxiv.org/pdf/2409.01666) | The paper revisits the use of Retrieval-Augmented Generation (RAG) for long-context answer generation, despite the emergence of long-context Large Language Models (LLMs) that can incorporate longer text sequences. The authors argue that extremely long contexts in LLMs can lead to a diminished focus on relevant information and decreased answer quality.<br><br> Key Contributions: <br> &nbsp; - Proposal of an Order-Preserve Retrieval-Augmented Generation (OP-RAG) mechanism that improves RAG performance for long-context question-answer applications. <br> &nbsp; - Discovery of an inverted U-shaped curve, where answer quality initially rises and then declines as the number of retrieved chunks increases. <br> &nbsp; - Identification of "sweet points" where OP-RAG achieves higher answer quality with fewer tokens than long-context LLMs. <br><br> Main Claim: <br> &nbsp; The paper claims that OP-RAG can outperform long-context LLMs in certain scenarios, making it a viable solution for long-context answer generation. | RAG for long-context answer generation |
| [Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation](https://arxiv.org/pdf/2409.03271v1) | The paper addresses the instability of Chain-of-Thought (CoT) methods in large language models (LLMs), which can lead to suboptimal reasoning performance. To overcome this, the authors propose the Strategic Chain-of-Thought (SCoT) methodology.<br><br> Key Contributions: <br> &nbsp; - SCoT integrates strategic knowledge to refine LLM performance by generating high-quality CoT paths and final answers.<br> &nbsp; - A two-stage approach is employed within a single prompt: eliciting an effective problem-solving strategy, followed by guided generation of CoT paths and final answers.<br> &nbsp; - Experimental results show significant improvements on eight challenging reasoning datasets, including a 21.05% increase on the GSM8K dataset and 24.13% on the Tracking Objects dataset.<br><br> Main Claim: <br> &nbsp; The paper claims that SCoT substantially enhances LLM performance in complex reasoning tasks, demonstrating its potential as a novel methodology for improving CoT methods. | Chain-of-Thought |
| [Large Language Model-Based Agents for Software Engineering: A Survey](https://arxiv.org/pdf/2409.02977) | The paper presents a comprehensive survey on Large Language Model (LLM)-based agents in the context of Software Engineering (SE). <br><br> Key Contributions: <br> &nbsp; - The survey collects and categorizes 106 papers on LLM-based agents for SE from two perspectives: SE and agent perspectives. <br> &nbsp; - The paper discusses the effectiveness of LLM-based agents in SE and their potential in tackling complex real-world problems through synergy with multiple agents and human interaction. <br> &nbsp; - The survey highlights open challenges and future directions in this critical domain. <br><br> Main Claim: <br> &nbsp; The paper aims to provide a systematic understanding of the current state of LLM-based agents in SE, identifying areas of promise and challenges for future research. <br><br> Additional Resource: <br> &nbsp; The survey's repository is available at https://github.com/FudanSELab/Agent4SE-Paper-List. | LLM Agents |
| [OLMoE: Open Mixture-of-Experts Language Models](https://arxiv.org/pdf/2409.02060) | The paper introduces OLMOE, a state-of-the-art language model that leverages sparse Mixture-of-Experts (MoE) architecture.<br><br> Key Contributions: <br> &nbsp; - OLMOE-1B-7B has 7 billion parameters but uses only 1 billion per input token, making it efficient. <br> &nbsp; - The model is pretrained on 5 trillion tokens and further adapted to create OLMOE-1B-7B-INSTRUCT. <br> &nbsp; - OLMOE outperforms other models with similar active parameters, including larger ones like Llama2-13B-Chat and DeepSeekMoE-16B.<br><br> Main Claim: <br> &nbsp; The paper claims that OLMOE is a highly efficient and effective language model that achieves state-of-the-art results while being fully open-sourced.  <br><br> Open-Source Resources: <br> &nbsp; - Model weights: https://hf.co/allenai/OLMoE-1B-7B-0924 <br> &nbsp; - Training data: https://hf.co/datasets/allenai/OLMoE-mix-0924 <br> &nbsp; - Code: https://github.com/allenai/OLMoE <br> &nbsp; - Logs: https://wandb.ai/ai2-llm/olmoe/reports/| Mixture-of-Experts Language Models |
| [Beyond Preferences in AI Alignment](https://arxiv.org/pdf/2408.16984) | The paper challenges the dominant practice of AI alignment, which assumes that human preferences are an adequate representation of human values and that AI systems should be aligned with these preferences. The authors argue that this "preferentist approach" has limitations and propose alternative conceptual and technical frameworks for AI alignment.<br><br> Key Points: <br> &nbsp; - The paper critiques the use of rational choice theory and expected utility theory (EUT) as a basis for AI alignment, arguing that they fail to capture the complexity of human values and neglect the possibility of incommensurable values. <br> &nbsp; - The authors propose a reframing of AI alignment, where AI systems are aligned with normative standards appropriate to their social roles, rather than with human preferences. <br> &nbsp; - This alternative approach emphasizes the importance of negotiating and agreeing upon normative standards with all relevant stakeholders, allowing for a multiplicity of AI systems to serve diverse ends while promoting mutual benefit and limiting harm.<br><br> Main Claim: <br> &nbsp; The paper argues that the preferentist approach to AI alignment is inadequate and that a new framework is needed to ensure that AI systems are aligned with human values and promote beneficial outcomes. | Beyond Preference in AI Alignment  |
|  |  |  |


## Week 2/4
| Title | Summary | Topics |
| --- | --- | --- |
| [Learning to Reason with LLMs](https://openai.com/index/learning-to-reason-with-llms/) | OpenAI o1â€”a new series of AI models designed to spend more time thinking before they respond. These models can reason through complex tasks and solve harder problems than previous models in science, coding, and math. o1 ranks in the 89th percentile on competitive programming questions, places among the top 500 students in the US in a qualifier for the USA Math Olympiad, and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems. | Large Language Models |
| [Chai-1: Decoding the molecular interactions of life](https://www.chaidiscovery.com/blog/introducing-chai-1) | A new multi-modal foundation model for molecular structure prediction that performs at the state-of-the-art across a variety of tasks relevant to drug discovery. Chai-1 enables unified prediction of proteins, small molecules, DNA, RNA, covalent modifications, and more. <br><br> Ope-Source Resources: <br> &nbsp; - Github: https://github.com/chaidiscovery/chai-lab <br> &nbsp; - Try yourself: http://lab.chaidiscovery.com/ | Multi-Modal Foundation Model |
| [Can LLMs Generate Novel Research Ideas?](https://arxiv.org/pdf/2409.04109) | This study evaluates the ability of large language models (LLMs) to generate novel, expert-level research ideas. The experiment compared ideas generated by LLMs with those produced by over 100 NLP researchers. The results showed that:  <br> &nbsp; - LLM-generated ideas were judged as more novel (p < 0.05) than human expert ideas. <br> &nbsp; - LLM-generated ideas were slightly weaker on feasibility.  <br><br>However, the study also identified open problems in building and evaluating research agents, including: <br> &nbsp; - LLM self-evaluation failures <br> &nbsp; - Lack of diversity in generation  <br><br> The authors propose a follow-up study to execute the generated ideas into full projects, enabling the evaluation of whether novelty and feasibility judgements result in meaningful differences in research outcomes. <br><br>Related GitHub Repository: https://github.com/NoviScl/AI-Researcher | LLMs on Research |
| [Agent Memory Workflow (AWM)](https://arxiv.org/pdf/2409.07429) | Current language-based agents struggle with long-horizon tasks and lack the ability to learn reusable task workflows from past experiences. <br><br>This paper aims to introduce "Agent Memory Workflow (AWM)", a method that can induce commonly reused task routines, called "workflows", and selectively provide them to agents to guide their future actions. This can help language model-based agents solve complex real-world tasks, such as web navigation. <br><br> Methodology: The authors propose two ways to implement AWM: <br> &nbsp; 1. Offline AWM: Workflows are induced from available training examples and integrated into the agent's memory before solving test tasks.<br> &nbsp; 2. Online AWM: Workflows are induced from the agent's own predictions on test tasks and continuously added to the agent's memory during inference. <br><br>Results and findings: This approach has shown significant improvements in web navigation tasks, covering 1000+ tasks from 200+ domains, with: <br> &nbsp; 1. 24.6% relative success rate increase on the Mind2Web benchmark <br> &nbsp; 2. 51.1% relative success rate increase on the WebArena benchmark <br><br>AWM also demonstrates strong generalization abilities, outperforming baselines by 8.9-14.0 absolute points on cross-website and cross-domain evaluations. | Agents |
| [DataGemma: Using real-world data to address AI hallucinations](https://docs.datacommons.org/papers/DataGemma-FullPaper.pdf) | DataGemma, a new set of open models that combines the strengths of Large Language Models (LLMs) with the real-world statistical data from Data Commons. This approach enables users to ask natural language questions and receive accurate answers, backed by verifiable data sources, addressing AI Hallucinations. <br><br> Key Points: <br> &nbsp; - Hybrid approach: Combines LLMs with Data Commons (a knowledge graph containing over 240 billion data points from sources like the UN, WHO,, CDC and Census Bureaus) to provide accurate and reliable answers. <br> &nbsp; - the idea lies in its two distinct approaches:  <br> &nbsp; &nbsp; - Retrieval-Interleaved Generation (RIG): Proactively queries Data Commons during response generation to assess response accuracy, and  <br> &nbsp; &nbsp; - Retrieval-Augmented Generation (RAG): Retrieves relevant context for generating response <br><br> Training and Architecture: <br> &nbsp; - Training: It is built on Google's Gemma architecture and trained on TPUv5e using JAX on synthetically generated data by Gemini 1.5. <br> &nbsp; - Data Commons Integration: Utilises Data Commons' vast resources to fetch relevant tables and data. <br> &nbsp; - RIG Evaluation Tool: Employs a two-stage evaluation process to assess response accuracy.<br><br> Performance Benchmarks and Metrics: <br> &nbsp; - Factual Accuracy: Achieves 58% accuracy in factual accuracy metrics, outperforming baseline models. <br> &nbsp; - Comparison to Baseline Models: Improves factuality from 5-17% to 58% in certain scenarios. <br> &nbsp; - Error Analysis: Identifies areas for improvement, including cases where both Data Commons and LLM responses are incorrect.<br><br> Limitations: <br> &nbsp; - Potential for Controversial Responses: May produce responses that are controversial, inflammatory or outdated since it relies primarily on one knowledge source - Data Commons. <br> &nbsp; - Performance concerns: The computational overhead and impact on inference time when using this two-stage solution in real-world application are of concern. | RAG and Hallucination |
| [LLaMA-Omni](https://arxiv.org/pdf/2409.06666) | Llama-Omni is a model architecture for low-latency speech interaction with LLMs.  <br><br> Key Points: <br> &nbsp; - Apparently, this is the open-source answer to GPT-4o real-time speech interaction and it is based on Llama-3.1-8B-Instruct.  <br> &nbsp; - Llama-Omni can simultaneously generate both text and speech responses given speech instructions.  <br> &nbsp; - Responses can be generated with a response latency as low as 226ms. <br> &nbsp; - Architecture-wise, it involves a speech encoder (Whisper-large-v3), a speech adaptor, an LLM, and a speech decoder. <br> &nbsp; - They also created InstructS2S-200K, a dataset of 200K speech instructions and responses, to align the model with speech interaction scenarios. <br> &nbsp; - training LLaMA-Omni takes less than 3 days on just 4 GPUs, paving the way for the efficient development of speech-language models in the future <br><br> Code and model: https://github.com/ictnlp/LLaMA-Omni | Speech interaction with LLMs |
|  |  |  |


## Week 3/4
| Title | Summary | Topics |
| --- | --- | --- |
| [Moshi: a speech-text foundation model for real-time dialogue](https://kyutai.org/Moshi.pdf) | The paper introduces Moshi: a speech-text foundation model and full-duplex spoken dialogue framework. <br> they present several components of the systems: <br> &nbsp; - Helium is a 7B parameter text LLM <br> &nbsp; -  Mimi is a semantic-acoustic neural audio code with state-of-the-art performance on audio quality  <br> &nbsp; - a hierarchical multi-stream architecture that can generate arbitrary conversation in a speech-to-speech manner. <br><br> &nbsp; - git repo: https://t.co/PFak47FMrm <br> &nbsp; - HuggingFace: https://t.co/bqG4IS0ntg| Speech-text Foundation model |
|  |  |  |
|  |  |  |


## Week 4/4
| Title | Summary | Topics |
| --- | --- | --- |
| []() |  | |
|  |  |  |
