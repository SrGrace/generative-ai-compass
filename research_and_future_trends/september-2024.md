# Best Gen AI Papers of the month - weekly updates (September 2024)

## Week 1/4
| Title | Summary | Topics |
| --- | --- | --- |
| [RAG in the Era of Long-Context LLMs](https://arxiv.org/pdf/2409.01666) | The paper revisits the use of Retrieval-Augmented Generation (RAG) for long-context answer generation, despite the emergence of long-context Large Language Models (LLMs) that can incorporate longer text sequences. The authors argue that extremely long contexts in LLMs can lead to a diminished focus on relevant information and decreased answer quality.<br><br> Key Contributions: <br> &nbsp; - Proposal of an Order-Preserve Retrieval-Augmented Generation (OP-RAG) mechanism that improves RAG performance for long-context question-answer applications. <br> &nbsp; - Discovery of an inverted U-shaped curve, where answer quality initially rises and then declines as the number of retrieved chunks increases. <br> &nbsp; - Identification of "sweet points" where OP-RAG achieves higher answer quality with fewer tokens than long-context LLMs. <br><br> Main Claim: <br> &nbsp; The paper claims that OP-RAG can outperform long-context LLMs in certain scenarios, making it a viable solution for long-context answer generation. | RAG for long-context answer generation |
| [Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation](https://arxiv.org/pdf/2409.03271v1) | The paper addresses the instability of Chain-of-Thought (CoT) methods in large language models (LLMs), which can lead to suboptimal reasoning performance. To overcome this, the authors propose the Strategic Chain-of-Thought (SCoT) methodology.<br><br> Key Contributions: <br> &nbsp; - SCoT integrates strategic knowledge to refine LLM performance by generating high-quality CoT paths and final answers.<br> &nbsp; - A two-stage approach is employed within a single prompt: eliciting an effective problem-solving strategy, followed by guided generation of CoT paths and final answers.<br> &nbsp; - Experimental results show significant improvements on eight challenging reasoning datasets, including a 21.05% increase on the GSM8K dataset and 24.13% on the Tracking Objects dataset.<br><br> Main Claim: <br> &nbsp; The paper claims that SCoT substantially enhances LLM performance in complex reasoning tasks, demonstrating its potential as a novel methodology for improving CoT methods. | Chain-of-Thought |
| [Large Language Model-Based Agents for Software Engineering: A Survey](https://arxiv.org/pdf/2409.02977) | The paper presents a comprehensive survey on Large Language Model (LLM)-based agents in the context of Software Engineering (SE). <br><br> Key Contributions: <br> &nbsp; - The survey collects and categorizes 106 papers on LLM-based agents for SE from two perspectives: SE and agent perspectives. <br> &nbsp; - The paper discusses the effectiveness of LLM-based agents in SE and their potential in tackling complex real-world problems through synergy with multiple agents and human interaction. <br> &nbsp; - The survey highlights open challenges and future directions in this critical domain. <br><br> Main Claim: <br> &nbsp; The paper aims to provide a systematic understanding of the current state of LLM-based agents in SE, identifying areas of promise and challenges for future research. <br><br> Additional Resource: <br> &nbsp; The survey's repository is available at https://github.com/FudanSELab/Agent4SE-Paper-List. | LLM Agents |
| [OLMoE: Open Mixture-of-Experts Language Models](https://arxiv.org/pdf/2409.02060) | The paper introduces OLMOE, a state-of-the-art language model that leverages sparse Mixture-of-Experts (MoE) architecture.<br><br> Key Contributions: <br> &nbsp; - OLMOE-1B-7B has 7 billion parameters but uses only 1 billion per input token, making it efficient. <br> &nbsp; - The model is pretrained on 5 trillion tokens and further adapted to create OLMOE-1B-7B-INSTRUCT. <br> &nbsp; - OLMOE outperforms other models with similar active parameters, including larger ones like Llama2-13B-Chat and DeepSeekMoE-16B.<br><br> Main Claim: <br> &nbsp; The paper claims that OLMOE is a highly efficient and effective language model that achieves state-of-the-art results while being fully open-sourced.  <br><br> Open-Source Resources: <br> &nbsp; - Model weights: https://hf.co/allenai/OLMoE-1B-7B-0924 <br> &nbsp; - Training data: https://hf.co/datasets/allenai/OLMoE-mix-0924 <br> &nbsp; - Code: https://github.com/allenai/OLMoE <br> &nbsp; - Logs: https://wandb.ai/ai2-llm/olmoe/reports/| Mixture-of-Experts Language Models |
| [Beyond Preferences in AI Alignment](https://arxiv.org/pdf/2408.16984) | The paper challenges the dominant practice of AI alignment, which assumes that human preferences are an adequate representation of human values and that AI systems should be aligned with these preferences. The authors argue that this "preferentist approach" has limitations and propose alternative conceptual and technical frameworks for AI alignment.<br><br> Key Points: <br> &nbsp; - The paper critiques the use of rational choice theory and expected utility theory (EUT) as a basis for AI alignment, arguing that they fail to capture the complexity of human values and neglect the possibility of incommensurable values. <br> &nbsp; - The authors propose a reframing of AI alignment, where AI systems are aligned with normative standards appropriate to their social roles, rather than with human preferences. <br> &nbsp; - This alternative approach emphasizes the importance of negotiating and agreeing upon normative standards with all relevant stakeholders, allowing for a multiplicity of AI systems to serve diverse ends while promoting mutual benefit and limiting harm.<br><br> Main Claim: <br> &nbsp; The paper argues that the preferentist approach to AI alignment is inadequate and that a new framework is needed to ensure that AI systems are aligned with human values and promote beneficial outcomes. | Beyond Preference in AI Alignment  |
|  |  |  |


## Week 2/4
| Title | Summary | Topics |
| --- | --- | --- |
| [Learning to Reason with LLMs](https://openai.com/index/learning-to-reason-with-llms/) | OpenAI o1—a new series of AI models designed to spend more time thinking before they respond. These models can reason through complex tasks and solve harder problems than previous models in science, coding, and math. o1 ranks in the 89th percentile on competitive programming questions, places among the top 500 students in the US in a qualifier for the USA Math Olympiad, and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems. | Large Language Models |
| [Chai-1: Decoding the molecular interactions of life](https://www.chaidiscovery.com/blog/introducing-chai-1) | A new multi-modal foundation model for molecular structure prediction that performs at the state-of-the-art across a variety of tasks relevant to drug discovery. Chai-1 enables unified prediction of proteins, small molecules, DNA, RNA, covalent modifications, and more. <br><br> Ope-Source Resources: <br> &nbsp; - Github: https://github.com/chaidiscovery/chai-lab <br> &nbsp; - Try yourself: http://lab.chaidiscovery.com/ | Multi-Modal Foundation Model |
| [Can LLMs Generate Novel Research Ideas?](https://arxiv.org/pdf/2409.04109) | This study evaluates the ability of large language models (LLMs) to generate novel, expert-level research ideas. The experiment compared ideas generated by LLMs with those produced by over 100 NLP researchers. The results showed that:  <br> &nbsp; - LLM-generated ideas were judged as more novel (p < 0.05) than human expert ideas. <br> &nbsp; - LLM-generated ideas were slightly weaker on feasibility.  <br><br>However, the study also identified open problems in building and evaluating research agents, including: <br> &nbsp; - LLM self-evaluation failures <br> &nbsp; - Lack of diversity in generation  <br><br> The authors propose a follow-up study to execute the generated ideas into full projects, enabling the evaluation of whether novelty and feasibility judgements result in meaningful differences in research outcomes. <br><br>Related GitHub Repository: https://github.com/NoviScl/AI-Researcher | LLMs on Research |
| [Agent Memory Workflow (AWM)](https://arxiv.org/pdf/2409.07429) | Current language-based agents struggle with long-horizon tasks and lack the ability to learn reusable task workflows from past experiences. <br><br>This paper aims to introduce "Agent Memory Workflow (AWM)", a method that can induce commonly reused task routines, called "workflows", and selectively provide them to agents to guide their future actions. This can help language model-based agents solve complex real-world tasks, such as web navigation. <br><br> Methodology: The authors propose two ways to implement AWM: <br> &nbsp; 1. Offline AWM: Workflows are induced from available training examples and integrated into the agent's memory before solving test tasks.<br> &nbsp; 2. Online AWM: Workflows are induced from the agent's own predictions on test tasks and continuously added to the agent's memory during inference. <br><br>Results and findings: This approach has shown significant improvements in web navigation tasks, covering 1000+ tasks from 200+ domains, with: <br> &nbsp; 1. 24.6% relative success rate increase on the Mind2Web benchmark <br> &nbsp; 2. 51.1% relative success rate increase on the WebArena benchmark <br><br>AWM also demonstrates strong generalization abilities, outperforming baselines by 8.9-14.0 absolute points on cross-website and cross-domain evaluations. | Agents |
| [DataGemma: Using real-world data to address AI hallucinations](https://docs.datacommons.org/papers/DataGemma-FullPaper.pdf) | DataGemma, a new set of open models that combines the strengths of Large Language Models (LLMs) with the real-world statistical data from Data Commons. This approach enables users to ask natural language questions and receive accurate answers, backed by verifiable data sources, addressing AI Hallucinations. <br><br> Key Points: <br> &nbsp; - Hybrid approach: Combines LLMs with Data Commons (a knowledge graph containing over 240 billion data points from sources like the UN, WHO,, CDC and Census Bureaus) to provide accurate and reliable answers. <br> &nbsp; - the idea lies in its two distinct approaches:  <br> &nbsp; &nbsp; - Retrieval-Interleaved Generation (RIG): Proactively queries Data Commons during response generation to assess response accuracy, and  <br> &nbsp; &nbsp; - Retrieval-Augmented Generation (RAG): Retrieves relevant context for generating response <br><br> Training and Architecture: <br> &nbsp; - Training: It is built on Google's Gemma architecture and trained on TPUv5e using JAX on synthetically generated data by Gemini 1.5. <br> &nbsp; - Data Commons Integration: Utilises Data Commons' vast resources to fetch relevant tables and data. <br> &nbsp; - RIG Evaluation Tool: Employs a two-stage evaluation process to assess response accuracy.<br><br> Performance Benchmarks and Metrics: <br> &nbsp; - Factual Accuracy: Achieves 58% accuracy in factual accuracy metrics, outperforming baseline models. <br> &nbsp; - Comparison to Baseline Models: Improves factuality from 5-17% to 58% in certain scenarios. <br> &nbsp; - Error Analysis: Identifies areas for improvement, including cases where both Data Commons and LLM responses are incorrect.<br><br> Limitations: <br> &nbsp; - Potential for Controversial Responses: May produce responses that are controversial, inflammatory or outdated since it relies primarily on one knowledge source - Data Commons. <br> &nbsp; - Performance concerns: The computational overhead and impact on inference time when using this two-stage solution in real-world application are of concern. | RAG and Hallucination |
| [LLaMA-Omni](https://arxiv.org/pdf/2409.06666) | Llama-Omni is a model architecture for low-latency speech interaction with LLMs.  <br><br> Key Points: <br> &nbsp; - Apparently, this is the open-source answer to GPT-4o real-time speech interaction and it is based on Llama-3.1-8B-Instruct.  <br> &nbsp; - Llama-Omni can simultaneously generate both text and speech responses given speech instructions.  <br> &nbsp; - Responses can be generated with a response latency as low as 226ms. <br> &nbsp; - Architecture-wise, it involves a speech encoder (Whisper-large-v3), a speech adaptor, an LLM, and a speech decoder. <br> &nbsp; - They also created InstructS2S-200K, a dataset of 200K speech instructions and responses, to align the model with speech interaction scenarios. <br> &nbsp; - training LLaMA-Omni takes less than 3 days on just 4 GPUs, paving the way for the efficient development of speech-language models in the future <br><br> Code and model: https://github.com/ictnlp/LLaMA-Omni | Speech interaction with LLMs |
|  |  |  |


## Week 3/4
| Title | Summary | Topics |
| --- | --- | --- |
| [Moshi: a speech-text foundation model for real-time dialogue](https://kyutai.org/Moshi.pdf) | The paper introduces Moshi: a speech-text foundation model and full-duplex spoken dialogue framework. <br> they present several components of the systems: <br> &nbsp; - Helium is a 7B parameter text LLM <br> &nbsp; -  Mimi is a semantic-acoustic neural audio code with state-of-the-art performance on audio quality  <br> &nbsp; - a hierarchical multi-stream architecture that can generate arbitrary conversation in a speech-to-speech manner. <br><br> &nbsp; - git repo: https://t.co/PFak47FMrm <br> &nbsp; - HuggingFace: https://t.co/bqG4IS0ntg| Speech-text Foundation model |
| [Training LLMs to Self-Correct via RL](https://arxiv.org/pdf/2409.12917) | This breakthrough uses reinforcement learning to enhance LLMs' self-correction abilities. Traditional fine-tuning falls short, so they developed a two-stage approach: first optimizing correction behaviour, then amplifying self-correction during training. Applied to Gemini models, it improved self-correction by up to 15.6% on benchmark tests! | LLMs |
| [Qwen2.5-Coder](https://arxiv.org/pdf/2409.12186) | A series of models including 1.5B and 7B parameters; it’s built upon the Qwen2.5 architecture which is continuously pretrained on 5.5 trillion tokens; achieves state-of-the-art performance across more than 10 benchmarks; includes strong capabilities in code generation, completion, reasoning, and repairing. | Code Model |
| [On the Diagram of Thought](https://arxiv.org/pdf/2409.10038) | 🔑 Key Insights:  <br><br> &nbsp; 🔹 DoT models iterative reasoning as a directed acyclic graph (DAG) within a single LLM <br> &nbsp; 🔹 Enables exploration of complex reasoning pathways while maintaining logical consistency <br> &nbsp; 🔹 Organizes propositions, critiques, refinements, and verifications into a cohesive structure <br> &nbsp; 🔹 Leverages auto-regressive next-token prediction with role-specific tokens <br> &nbsp; 🔹 Formalizes the framework using Topos Theory for mathematical rigor - In case you're wondering like me 🤔 ...Imagine you're building a complex Lego structure. Topos Theory is like a super-advanced set of Lego building rules that helps you construct and understand incredibly complex structures, not just with plastic bricks, but with ideas and logic. | AI Reasoning |
| [TO COT OR NOT TO COT?](https://arxiv.org/pdf/2409.12183) | This meta-analysis of over 100 papers reveals that Chain-of-Thought (CoT) prompting shines brightest in math and logic tasks. It significantly improves symbolic execution, but interestingly, dedicated symbolic solvers still have an edge. It's a reminder that even powerful techniques have their sweet spots! | Prompting |
| [Iteration of Thought](https://arxiv.org/pdf/2409.12618) | IoT introduces a dynamic framework that adapts reasoning paths on the fly. Unlike rigid processes, IoT uses an inner dialogue agent to guide and adjust reasoning. It's like giving AI the power of real-time self-reflection and course correction! | AI Reasoning |
| [Jailbreaking Large Language Models with Symbolic Mathematics](https://arxiv.org/pdf/2409.11445) | Researchers used GPT-4 to generate mathematically encoded prompts that bypass AI safety measures with a 73.6% success rate across 13 state-of-the-art models. It's a critical discovery highlighting the need for more robust safety mechanisms in AI. | Prompting |
|  |  |  |


## Week 4/4
| Title | Summary | Topics |
| --- | --- | --- |
| [SMALL LANGUAGE MODELS: SURVEY, MEASUREMENTS, AND INSIGHTS](https://arxiv.org/pdf/2409.15790) | 🔑 Key Highlights: <br><br> &nbsp; [1]. SLM Overview: Focusing on models with 100M–5B parameters, SLMs are designed to operate efficiently on devices like smartphones, IoT gadgets, and wearables, in contrast to large language models (LLMs) running in data centres.<br> &nbsp; [2]. Architectural Innovations: SLMs are shifting to use Group-Query Attention and Gated Feed Forward Networks (FFNs), replacing older multi-head attention mechanisms, significantly improving their on-device performance.<br> &nbsp; [3]. Benchmarking: Over 59 SLMs were evaluated across multiple dimensions—commonsense reasoning, in-context learning, mathematics, and coding—showing SLMs are closing the gap with LLMs, especially in problem-solving and reasoning tasks.<br> &nbsp; [4]. On-device Performance: Analysis of inference latency and memory usage shows SLMs are optimized for on-device environments, significantly reducing memory footprint and latency.<br> &nbsp; [5]. Data Quality Over Quantity: Training on high-quality datasets like DCLM and FineWeb-Edu is critical to SLM performance. The recent trend in SLM research is filtering data with model-based methods to achieve better performance on less training data.<br> &nbsp; [6]. In-Context Learning: SLMs have shown strong improvements in in-context learning, with models like Gemma 2 showing a 4.8% accuracy increase through 5-shot learning on complex tasks.<br> &nbsp; [7]. Over-Training for Deployment: Contrary to Chinchilla Law (- In case you're wondering like me 🤔...This law basically suggests the optimal balance between model size and training data for maximum efficiency, reducing computational costs without sacrificing performance), many SLMs are "over-trained" on more tokens than predicted for their size, optimizing them for deployment on resource-constrained devices.<br> &nbsp; [8]. Collaborative AI: Future research suggests hybrid approaches where SLMs handle easier tasks locally, while cloud-based LLMs tackle more complex problems, improving device-cloud collaboration.<br><br>💡 Looking Ahead:<br> &nbsp; 🔹Co-design of SLM architectures and hardware is vital to further optimize performance.<br> &nbsp; 🔹Continual learning for personalization will enable SLMs to adapt to user preferences, while keeping data secure.<br> &nbsp; 🔹Sparse SLMs and their impact on device memory and computation are underexplored areas with great potential. | SLMs |
| [RAG and Beyond](https://arxiv.org/pdf/2409.14924v1) | 🔑 Key Takeaways: <br><br> &nbsp; [𝟭] 𝗣𝘂𝗿𝗽𝗼𝘀𝗲 𝗼𝗳 𝗘𝘅𝘁𝗲𝗿𝗻𝗮𝗹 𝗗𝗮𝘁𝗮 𝗜𝗻𝘁𝗲𝗴𝗿𝗮𝘁𝗶𝗼𝗻: Using external data enhances domain-specific expertise, temporal relevance, and reduces hallucination in LLMs, making outputs more controllable and interpretable. <br> &nbsp; [𝟮] 𝗙𝗼𝘂𝗿 𝗧𝘆𝗽𝗲𝘀 𝗼𝗳 𝗤𝘂𝗲𝗿𝘆 𝗖𝗼𝗺𝗽𝗹𝗲𝘅𝗶𝘁𝗶𝗲𝘀: <br> &nbsp; &nbsp; 🔸 𝗟𝗲𝘃𝗲𝗹 𝟭: 𝗘𝘅𝗽𝗹𝗶𝗰𝗶𝘁 𝗙𝗮𝗰𝘁 𝗤𝘂𝗲𝗿𝗶𝗲𝘀: Direct fact retrieval from documents (e.g., “Who is the PM of India?”). <br> &nbsp; &nbsp;🔸 𝗟𝗲𝘃𝗲𝗹 𝟮: 𝗜𝗺𝗽𝗹𝗶𝗰𝗶𝘁 𝗙𝗮𝗰𝘁 𝗤𝘂𝗲𝗿𝗶𝗲𝘀: Requires basic reasoning or combining multiple pieces of data (e.g., “Who is the President of the country where New Delhi is located?”). <br> &nbsp; &nbsp;🔸 𝗟𝗲𝘃𝗲𝗹 𝟯: 𝗜𝗻𝘁𝗲𝗿𝗽𝗿𝗲𝘁𝗮𝗯𝗹𝗲 𝗥𝗮𝘁𝗶𝗼𝗻𝗮𝗹𝗲 𝗤𝘂𝗲𝗿𝗶𝗲𝘀: Needs domain-specific logic or rules from manuals (e.g., applying FDA guidelines for drug approval). <br> &nbsp; &nbsp;🔸 𝗟𝗲𝘃𝗲𝗹 𝟰: 𝗛𝗶𝗱𝗱𝗲𝗻 𝗥𝗮𝘁𝗶𝗼𝗻𝗮𝗹𝗲 𝗤𝘂𝗲𝗿𝗶𝗲𝘀: Involves deeper, implicit patterns not explicitly stated, such as inferring economic impacts. <br> &nbsp; [𝟯] 𝗧𝗲𝗰𝗵𝗻𝗶𝗾𝘂𝗲𝘀 𝗳𝗼𝗿 𝗘𝘅𝘁𝗲𝗿𝗻𝗮𝗹 𝗗𝗮𝘁𝗮 𝗜𝗻𝘁𝗲𝗴𝗿𝗮𝘁𝗶𝗼𝗻: <br> &nbsp; &nbsp;🔸 𝗖𝗼𝗻𝘁𝗲𝘅𝘁-𝗯𝗮𝘀𝗲𝗱 𝗜𝗻𝘁𝗲𝗴𝗿𝗮𝘁𝗶𝗼𝗻: Injecting relevant external data as context for better grounding. <br> &nbsp; &nbsp;🔸 𝗦𝗺𝗮𝗹𝗹 𝗠𝗼𝗱𝗲𝗹 𝗔𝘀𝘀𝗶𝘀𝘁𝗮𝗻𝗰𝗲: Use of smaller models trained on specific data to guide the LLM’s reasoning. <br> &nbsp; &nbsp;🔸 𝗙𝗶𝗻𝗲-𝗧𝘂𝗻𝗶𝗻𝗴: Directly modifying LLM weights to adapt to specialized fields. <br> &nbsp; [𝟰] 𝗖𝗵𝗮𝗹𝗹𝗲𝗻𝗴𝗲𝘀 𝗶𝗻 𝗥𝗲𝗮𝗹-𝗪𝗼𝗿𝗹𝗱 𝗦𝗰𝗲𝗻𝗮𝗿𝗶𝗼𝘀: <br> &nbsp; &nbsp;🔸 𝗘𝗳𝗳𝗶𝗰𝗶𝗲𝗻𝘁 𝗗𝗮𝘁𝗮 𝗥𝗲𝘁𝗿𝗶𝗲𝘃𝗮𝗹: Finding the right external data with precision. <br> &nbsp; &nbsp;🔸 𝗜𝗻𝘁𝗲𝗿𝗽𝗿𝗲𝘁𝗮𝗯𝗶𝗹𝗶𝘁𝘆 & 𝗖𝗼𝗻𝘁𝗿𝗼𝗹𝗹𝗮𝗯𝗶𝗹𝗶𝘁𝘆: Making the model’s decision-making transparent, especially in fields like healthcare and finance. <br> &nbsp; &nbsp;🔸 𝗧𝗮𝘀𝗸 𝗖𝗼𝗺𝗽𝗹𝗲𝘅𝗶𝘁𝘆 𝗠𝗮𝗻𝗮𝗴𝗲𝗺𝗲𝗻𝘁: Understanding when a task requires multiple capabilities to be disentangled for better results. <br> &nbsp; [𝟱] 𝗦𝗼𝗹𝘂𝘁𝗶𝗼𝗻𝘀: <br> &nbsp; &nbsp;🔸 𝗥𝗔𝗚 𝗙𝗿𝗮𝗺𝗲𝘄𝗼𝗿𝗸𝘀: Combining retrieval and generation, with techniques like iterative RAG and graph/tree-based methods. <br> &nbsp; &nbsp;🔸 𝗣𝗿𝗼𝗺𝗽𝘁 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿𝗶𝗻𝗴 - 𝗖𝗼𝗧, 𝗧𝗼𝗧, 𝗟𝗼𝗧 𝗲𝘁𝗰.: Enhancing LLM interpretability using structured reasoning paths. <br> &nbsp; &nbsp;🔸 𝗙𝗶𝗻𝗲-𝗧𝘂𝗻𝗶𝗻𝗴 𝘄𝗶𝘁𝗵 𝗥𝗲𝗱𝘂𝗰𝗲𝗱 𝗖𝗼𝘀𝘁𝘀: Using adapter tuning, LoRA etc. to minimize the cost of domain-specific fine-tuning.| RAG |
|  |  |  |
|  |  |  |
|  |  |  |
