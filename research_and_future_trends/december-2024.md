## Week 1/4
| Title | Summary | Topics |
| --- | --- | --- |
| [Large language models surpass human experts in predicting neuroscience results](https://www.nature.com/articles/s41562-024-02046-9) | This recent study published in Nature Human Behaviour unveils that LLMs trained on neuroscience literature outperform human neuroscientists in predicting experimental outcomes. 🌟 <br><br> The research introduces BrainBench, a benchmark designed to test LLMs’ ability to forecast experimental results in neuroscience.  <br><br> Results?  <br><br> LLMs achieved an accuracy of 81.4%, surpassing human experts' 63.4%.  <br><br> Even more exciting, a fine-tuned model called BrainGPT, trained with domain-specific knowledge, performed even better! 📈 <br><br> 🔑 Why is this groundbreaking? <br> &nbsp; 🔹 Forward-looking AI: Unlike traditional benchmarks, BrainBench focuses on predicting novel results, showcasing AI’s potential to shape future discoveries. <br> &nbsp; 🔹 Complementing humans: LLMs demonstrated confidence-calibrated predictions and tackled challenges that even experts struggled with, hinting at the possibility of powerful human-AI partnerships. <br> &nbsp; 🔹 Scalable innovation: From neuroscience to other domains, this approach is transferable, opening doors to revolutionize knowledge-intensive fields. 🚀 | LLMs |
| [Towards Adaptive Mechanism Activation in Language Agent](https://arxiv.org/pdf/2412.00722) | 🤔 Ever wondered how language agents, like the ones powered by LLMs, tackle diverse and complex tasks?  <br><br> While their potential is immense, many agents rely on rigid, predefined mechanisms - limiting their ability to adapt to dynamic, real-world challenges. 🌍 <br><br> This is where ALAMA (Adaptive Language Agent Mechanism Activation Learning with Self-Exploration) steps in - a novel approach that combines adaptability with efficiency! 🧠 <br><br> 🔑 🔍 Key Insights: <br><br> Traditional agents activate fixed mechanisms (like reasoning, memory, or planning) in a pre-set sequence. ALAMA introduces a new level of flexibility: <br> &nbsp; 🔹 It uses a unified framework (UniAct) to integrate diverse mechanisms. <br> &nbsp; 🔹 Employs self-exploration to learn the best mechanism for a task, reducing reliance on costly manual data. <br> &nbsp; 🔹 Improves adaptability through advanced optimization techniques, leading to significant gains in performance. <br><br> 📊 In experiments, ALAMA consistently outperformed fixed-mechanism agents by dynamically adapting to task characteristics. For example: <br> &nbsp; 🔹 A 15%+ improvement in solving mechanism-sensitive problems. <br> &nbsp; 🔹 Strong generalization across unseen datasets - hinting at its potential for real-world applications in IT, healthcare, and beyond. | Agentic AI |
| [DataLab: A Unified Platform for LLM-Powered Business Intelligence](https://arxiv.org/pdf/2412.02205) | This recent paper introduces "DataLab", a unified platform powered by LLMs, designed to tackle this very challenge. <br><br> 💡 Key Insights: <br> &nbsp; 🔗 One-Stop BI Framework: Integrates data roles (engineers, analysts, scientists) into a seamless workflow, from SQL queries to Python code to dashboards - all in one computational notebook. <br> &nbsp; 📚 Enterprise-Grade Intelligence: Leverages domain-specific knowledge to handle ambiguous datasets and enterprise jargon effectively. <br> &nbsp; 🤝 Collaboration Redefined: Facilitates communication between AI agents using structured inter-agent protocols, ensuring tasks like visualization or anomaly detection happen without bottlenecks. <br> &nbsp; ⚡ Efficiency at Scale: Reduces token costs by up to 61.65% while boosting task accuracy by leveraging cell-based context management. <br><br> 📊 Results That Speak Volumes: Extensive experiments on real-world datasets from Tencent and industry benchmarks show that DataLab improves accuracy by up to 58.58% for BI-specific tasks. | BI |
| [COMPOSITION OF EXPERTS: A MODULAR COMPOUND AI SYSTEM LEVERAGING LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2412.01868) | This recent paper introduces "the Composition of Experts (CoE)": a modular compound AI system that dynamically combines expert LLMs using a clever routing mechanism. 🛤️📚 <br><br> 🔑 Key Features: <br> &nbsp; 1️⃣ Dynamic Routing: A router selects the best expert model for each input, reducing computational overhead. <br> &nbsp; 2️⃣ Scalability: Easily integrate new experts for specialized domains without retraining the entire system. <br> &nbsp; 3️⃣ Cost Efficiency: Uses fewer active parameters while achieving superior results. <br><br> ⚙️ Leveraging state-of-the-art architectures like SambaNova's SN40L, CoE showcases impressive performance improvements across benchmarks like Arena-Hard and MT-Bench.  <br><br> 💡 With modularity and robustness at its core, CoE could be a significant step towards economical and customizable AI solutions. 🌐 | LLMs |
| [HOW TO CORRECTLY DO SEMANTIC BACKPROPAGATION ON LANGUAGE-BASED AGENTIC SYSTEMS](https://arxiv.org/pdf/2412.03624) | Language-based agentic systems are stepping into the real world 🌍, solving complex tasks from natural language processing to web searches.  <br><br> But... <br><br> optimizing them has remained a tedious, manual process. <br><br> What if we could optimize these systems as seamlessly as training neural networks with backpropagation? <br><br> This interesting new approach - "Semantic Backpropagation", brings automatic optimization to the forefront by aligning with reverse-mode differentiation techniques like TextGrad.  <br><br> By representing AI agents as computational graphs, this method allows feedback to flow back to individual components through semantic gradients. <br><br> 🔍 On benchmarks like BIG-Bench Hard and GSM8K, Semantic Backpropagation doesn’t just keep up with existing methods—it outperforms them significantly. <br><br> This method is efficient, reducing complexity while delivering top-tier performance, paving the way for AI systems that autonomously optimize themselves. | Agentic AI |
| []() |  |  |


## Week 2/4
| Title | Summary | Topics |
| --- | --- | --- |
| [PROCESSBENCH: Identifying Process Errors in Mathematical Reasoning](https://arxiv.org/pdf/2412.06559) | This recent research proposes PROCESSBENCH, a novel benchmark designed to test AI's ability to catch its own errors in mathematical reasoning. 🧠✨ <br><br> 📊 Key Highlights:<br> &nbsp; 1️⃣ Challenging Problems: It includes 3,400 test cases with competition-level math problems, pushing AI to its limits.<br> &nbsp; 2️⃣ Error Focus: Instead of just checking the final answer, it zeroes in on step-by-step accuracy, a critical factor for real-world applications like education and programming.<br> &nbsp; 3️⃣ Battle of Models: Open-source models like QwQ-32B are catching up with proprietary giants like GPT-4, but there's still room for improvement in error detection and critique. <br><br> With advancements like these, we’re moving toward scalable oversight - AI systems that can not only solve problems but also identify where they went wrong. This is crucial for building reliable AI solutions in areas requiring precision, such as healthcare and engineering. | Reasoning Benchmark |
| [Training Large Language Models to Reason in a Continuous Latent Space](https://arxiv.org/pdf/2412.06769) | The paper introduces "Coconut" (Chain of Continuous Thought) 🥥 - a paradigm-shifting approach that lets LLMs reason in a continuous latent space, breaking free from the constraints of traditional language-based reasoning. <br><br> 🌟 Key Takeaways:<br> &nbsp;🔹 Why the change? Traditional reasoning methods like Chain-of-Thought (CoT) operate in "language space", which focuses on text coherence rather than effective reasoning. This can result in inefficiencies and suboptimal reasoning paths.<br> &nbsp;🔹 What is Coconut? Instead of expressing reasoning step-by-step in text, Coconut uses "continuous thoughts" (hidden states of the model) to represent and process reasoning directly in latent space. This unlocks powerful capabilities: <br> &nbsp; &nbsp; 🌐 Breadth-First Reasoning: Coconut can explore multiple reasoning paths simultaneously and eliminate dead ends later, unlike CoT, which prematurely commits to a single path. <br> &nbsp; &nbsp;  ⚡ Fewer Tokens, More Efficiency: Achieves higher reasoning accuracy with fewer words, making reasoning faster and leaner. <br><br> 🧠 Coconut outperforms CoT in logical reasoning tasks requiring complex planning and backtracking, such as solving directed acyclic graph problems (think multi-step puzzles 🧩).  <br><br> By reasoning in latent space, Coconut mimics advanced human-like problem-solving - focusing on planning and exploration rather than linguistic fluency. <br><br> 🛠️ This research could redefine how LLMs are deployed in domains like: <br> &nbsp; 📐 Mathematics and Theorem Proving <br> &nbsp;  🔬 Scientific Discovery <br> &nbsp;  🏥 Advanced Diagnostics and Decision-Making | LLM Reasoning |
| [LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods](https://arxiv.org/pdf/2412.05579) | LLMs aren't just producing text; they're now becoming the judges of their own outputs.  <br><br> This recent paper, LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods, explores this transformative concept. <br><br> Traditional evaluation metrics often fall short when assessing the nuanced capabilities of generative AI, such as creativity, coherence, or contextual accuracy.  <br><br> LLMs-as-Judges introduce a flexible, scalable, and interpretable approach that adapts to diverse tasks, offering human-like insights into performance. <br><br> 🔑 Key highlights: <br> &nbsp;🔹 Functionality: LLMs can assess quality, suggest refinements, and even enhance model training through feedback loops. <br> &nbsp;🔹 Applications: From summarization and translation to legal and medical fields, the potential is vast. <br> &nbsp;🔹 Challenges: Issues like bias, dependency on prompt engineering, and evaluation consistency remain critical hurdles. <br> &nbsp;🔹 Future Directions: Collaborative AI-human evaluation and cross-domain adaptability are exciting paths ahead! | LLMs-as-Judges |
| [Phi-4 Technical Report](https://arxiv.org/pdf/2412.08905) | 🧠 Can smaller AI models truly outperform giants? Microsoft's Phi-4 model shows they can - with the right approach!  <br><br> The Phi-4 language model, with just 14 billion parameters, challenges the notion that "bigger is always better" in AI. This model focuses on data quality and synthetic training techniques rather than sheer scale. <br><br> 🔑 What sets Phi-4 apart?<br> &nbsp;1️⃣ Synthetic data mastery: Instead of relying heavily on organic data like web content, Phi-4 incorporates synthetic datasets crafted through advanced techniques like multi-agent prompting and self-revision workflows. These enable the model to excel in reasoning-heavy tasks.<br> &nbsp;2️⃣ Smarter training: Phi-4 introduces innovations in curriculum design and post-training processes, such as Direct Preference Optimization (DPO), ensuring it learns effectively.<br> &nbsp;3️⃣ Benchmark-beating performance: Despite its size, Phi-4 surpasses larger models like GPT-4o in STEM benchmarks, including math competitions and graduate-level Q&A tests. 🏆 <br><br> Phi-4 proves that strategic data curation and training innovations can yield exceptional performance without the need for colossal models. 🌐 | LLMs |
| [ASYNCHRONOUS LLM FUNCTION CALLING](https://arxiv.org/pdf/2412.07017) | The paper proposes AsyncLM, a system for asynchronous LLM function calling; they design an in-context protocol for function calls and interrupts, provide fine-tuning strategy to adapt LLMs to the interrupt semantics, and implement these mechanisms efficiently on LLM inference process; AsyncLM can reduce task completion latency from 1.6x-5.4x compared to synchronous function calling; it enables LLMs to generate and execute function calls concurrently | LLMs |
| [Byte Latent Transformer: Patches Scale Better Than Tokens](https://scontent.fblr8-1.fna.fbcdn.net/v/t39.2365-6/470135129_1314438233309836_4712217603129928862_n.pdf?_nc_cat=111&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=n2qlO-fohvgQ7kNvgHLM3a0&_nc_zt=14&_nc_ht=scontent.fblr8-1.fna&_nc_gid=AD1DwqY5Cusu87Dd8If3Ggc&oh=00_AYCkuIcaAfbg3vs-FCgmEJ_jnCUjwrFdJts0LFN3cXUHlg&oe=676DE408) | The paper introduces a byte-level language model architecture that matches tokenization-based LLM performance while improving efficiency and robustness; uses a dynamic method of grouping bytes into patches based on the entropy of the next byte, allocating more compute resources to complex predictions while using larger patches for more predictable sequences; BLT demonstrates the ability to match or exceed the performance of models like Llama 3 while using up to 50% fewer FLOPs during inference. | Transformers |
| []() |  |  |


## Week 3/4
| Title | Summary | Topics |
| --- | --- | --- |
| [LMAgent: A Large-scale Multimodal Agents Society for Multi-user Simulation](https://arxiv.org/pdf/2412.09237) | LLMs have taken centre stage in building intelligent AI agents, but most existing systems are limited to a few agents, and only in text-based environments.  <br><br> This research introduces LMAgent - a large-scale multimodal society of 10,000+ AI agents that interact through rich, multimodal channels like text and images! 🌐 <br><br> 📦 What can LMAgent do? <br>In an e-commerce sandbox, LMAgent agents can shop, chat, browse, and even live-stream! They simulate realistic human behaviours such as:<br> &nbsp;🔹 Making autonomous decisions (e.g., browsing or buying products).<br> &nbsp;🔹 Exhibiting herd behaviours like group purchasing trends.<br> &nbsp;🔹 Mimicking social influence dynamics, such as how recommendations or peer reviews impact buying decisions. <br><br> 💡 How does it work? <br> &nbsp;1️⃣ Fast Memory Mechanism 🧠: By categorizing memory into short-term and long-term, agents compress and manage their experiences efficiently, improving performance while saving 40% of computational costs.<br> &nbsp; 2️⃣ Self-consistency Prompting 🗣️: This ensures agents make rational decisions by combining internal persona traits with external environmental data.<br> &nbsp; 3️⃣ Small-world Networks 🌍: Inspired by real-world social networks, this design enables faster communication between agents, mimicking how humans connect and influence each other. | Agents |
| []() |  |  |
| []() |  |  |


## Week 4/4
| Title | Summary | Topics |
| --- | --- | --- |
| []() |  |  |
| []() |  |  |
