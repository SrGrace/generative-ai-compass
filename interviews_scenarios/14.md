### Let's say your LLM struggles with financial QA - for example, understanding IFRS accounting rules. Would you fine-tune or prompt-engineer?
---

You: "Depends on three variables: data sensitivity, response variability, and inference cost."

Interviewer: "Explain."

You: "If the model frequently misinterprets domain-specific terms - say, impairment loss vs. write-off - prompt engineering may not fix it, because the model hasn’t internalized that domain semantics. Fine-tuning helps the model internalize these relationships."
"But if the gap is contextual adaptation (not factual misunderstanding), then structured prompting + retrieval augmentation does the job."

Interviewer: "So where’s the boundary?"

You:
Use prompt engineering when:
 - Domain knowledge is externalizable via retrieval (e.g., product manuals, docs).
 - Model performance depends more on contextual clarity than internal weights.
 - You need quick iteration and transparency.

Use fine-tuning when:
 - The model repeatedly fails to interpret domain-specific logic.
 - There's abundant domain QA or conversation data.
 - You need deterministic behavior (e.g., financial or legal assistants).

Interviewer: "What about hybrid approaches?"

You: "That’s often the sweet spot:
 - Start with RAG for quick wins.
 - Collect high-quality interactions over time.
 - Then fine-tune a smaller model (like Llama 3 8B) with those examples for latency + cost efficiency."

In short: don’t fine-tune for context gaps; fine-tune for conceptual gaps.
