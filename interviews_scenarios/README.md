1. [What’s the real bottleneck in LLM serving throughput - and how does PagedAttention fix it?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/1.md) 
2. [Your embedding lookups are painfully slow. What’s going on, and how do you fix it?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/2.md)
3. [We have a 200MB vision model: 5 FPS on our device, high power draw. How do you get it into production without killing accuracy?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/3.md)
4. [Vanilla Gradient Descent is quaint for huge models. What's your go-to optimizer when you're optimizing for scale, and why?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/4.md)
5. [Our team needs to build RAG over 10 million documents. Which vector database would you recommend and, crucially, why?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/5.md)
