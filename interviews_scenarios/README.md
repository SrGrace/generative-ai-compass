[1. Whatâ€™s the real bottleneck in LLM serving throughput - and how does PagedAttention fix it?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/1.md) 
[]()
[]()
[4. Vanilla Gradient Descent is quaint for huge models. What's your go-to optimizer when you're optimizing for scale, and why?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/4.md)
