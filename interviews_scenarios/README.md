1. [What’s the real bottleneck in LLM serving throughput - and how does PagedAttention fix it?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/1.md) 
2. [Your embedding lookups are painfully slow. What’s going on, and how do you fix it?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/2.md)
3. [We have a 200MB vision model: 5 FPS on our device, high power draw. How do you get it into production without killing accuracy?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/3.md)
4. [Vanilla Gradient Descent is quaint for huge models. What's your go-to optimizer when you're optimizing for scale, and why?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/4.md)
5. [Our team needs to build RAG over 10 million documents. Which vector database would you recommend and, crucially, why?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/5.md)
6. [We're building autonomous agents for complex, multi-step reasoning over extended periods. How do you tackle the long-term memory problem beyond just increasing context window size?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/6.md)
7. [We're serving billions of LLM inference requests daily across various applications. What caching strategies are you thinking about to maximize throughput and minimize latency?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/7.md)
8. [We're exploring next-generation AI agents for highly complex, open-ended tasks - think scientific discovery or strategic planning. What architectural paradigms go beyond simple 'plan-and-execute' to enable deep, adaptive reasoning?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/8.md)
9. [Why does chain-of-thought (CoT) reasoning improve LLM performance on complex tasks - but sometimes fails catastrophically?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/9.md)
10. [How does speculative decoding speed up LLM inference?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/10.md)
11. [Why do tool-using agents often hallucinate function calls even when APIs are available?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/11.md)
12. [Why do reflection-based agents degrade over long horizons?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/12.md)
13. [We're seeing incredible adoption of our new internal LLM-powered assistant, but inference costs are spiraling. How would you approach optimizing the inference pipeline for a model like Llama 3 8B, handling thousands of requests per second?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/13.md)
14. [Let's say your LLM struggles with financial QA - for example, understanding IFRS accounting rules. Would you fine-tune or prompt-engineer?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/14.md)
15. [Beyond increasing context window size, what are the most effective architectural and data-centric strategies you'd employ to enable an LLM to effectively reason over gigabytes of domain-specific, unstructured data?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/15.md)
16. [We want to build an autonomous agent system that can handle complex customer returns involving multiple departments. How would you architect this?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/16.md)
17. [We have a 200K token context window. How would you design an application that actually leverages this effectively?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/17.md)
18. [Everyone says tokenization just splits text. What’s really happening?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/18.md)
19. [We're exploring collaborative multi-agent systems - swarms of LLM-driven agents that negotiate, divide labor, and pursue shared goals. How would you design coordination and control mechanisms to avoid chaos and ensure convergence?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/19.md)
20. [A client has a RAG-based system that isn't giving accurate results. After investigation, you find the retrieval system is failing. How would you improve it?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/20.md)
21. [We need to predict product recommendations across billions of nodes. How do you scale a GNN?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/21.md)
22. [Siri operates on-device and relies heavily on understanding user intent from spoken language, often in noisy environments and with diverse accents. Describe how you would design an intent recognition system that is robust, privacy-preserving, and computationally efficient for on-device deployment.](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/22.md)
23. [We want to fine-tune a large language model on domain-specific documents. How would you approach it while avoiding catastrophic forgetting?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/23.md)
24. [We want to fine-tune an LLM sequentially on multiple domains without losing prior knowledge. How do you prevent catastrophic forgetting?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/24.md)
25. [We want an LLM to learn sequential tasks without forgetting previous ones. EWC (Elastic Weight Consolidation) works, but what other strategies would you consider?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/25.md)
26. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/26.md)
27. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/27.md)
28. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/28.md)
29. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/29.md)
30. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/30.md)
31. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/31.md)
32. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/32.md)
33. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/33.md)
34. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/34.md)
35. [](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/35.md)

