1. [What’s the real bottleneck in LLM serving throughput - and how does PagedAttention fix it?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/1.md) 
2. [Your embedding lookups are painfully slow. What’s going on, and how do you fix it?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/2.md)
3. []()
4. [Vanilla Gradient Descent is quaint for huge models. What's your go-to optimizer when you're optimizing for scale, and why?](https://github.com/SrGrace/generative-ai-compass/blob/main/interviews_scenarios/4.md)
