# ðŸ“š Foundational Concepts and Theories behind Generative AI with Resources

## Fundamental Concepts 

- Neural Networks
  - [3Blue1Brown Neural Network Video Series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)

- Deep Learning
  - [Deep Learning Book by Goodfellow, Bengio, and Courville](https://www.deeplearningbook.org/)

- Unsupervised Learning 
  - [Stanford CS229 Lecture on Unsupervised Learning](https://www.youtube.com/watch?v=QvuQH4_05LI)

- Representation Learning
  - [Representation Learning: A Review and New Perspectives](https://arxiv.org/abs/1206.5538)


## Generative Models

- Generative Adversarial Networks (GANs)
  - [Original GAN Paper](https://arxiv.org/abs/1406.2661)
  - [GAN Lab: Understanding GANs Interactively](https://poloclub.github.io/ganlab/)

- Variational Autoencoders (VAEs)
  - [Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908)

- Autoregressive Models
  - [PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications](https://arxiv.org/abs/1701.05517)

- Diffusion Models
  - [What are Diffusion Models? by Lilian Weng](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)

- Flow-based Models
  - [NICE: Non-linear Independent Components Estimation](https://arxiv.org/abs/1410.8516)


## Natural Language Processing

- Transformer Architecture
  - [The Illustrated Transformer by Jay Alammar](https://jalammar.github.io/illustrated-transformer/)

- Attention Mechanism
  - [Attention Is All You Need (Original Paper)](https://arxiv.org/abs/1706.03762)
  - [seq2seq and Attention by Lena Voita](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html#main_content)

- Large Language Models (LLMs)
  - [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)


## Computer Vision

- Convolutional Neural Networks (CNNs)
  - [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)

- Image-to-Image Translation
  - [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004)

- Style Transfer
  - [Neural Style Transfer: A Review](https://arxiv.org/abs/1705.04058)


## Probabilistic Graphical Models

- Bayesian Networks
  - [Probabilistic Graphical Models: Principles and Techniques](https://mitpress.mit.edu/books/probabilistic-graphical-models)

- Markov Random Fields
  - [An Introduction to Conditional Random Fields](https://arxiv.org/abs/1011.4088)


## Reinforcement Learning in Generation

- Policy Gradients for Generation
  - [Sequence Generative Adversarial Networks](https://arxiv.org/abs/1609.05473)

- Adversarial Reinforcement Learning
  - [Adversarial Reinforcement Learning](https://arxiv.org/abs/1706.02275)


## Optimization Techniques

- Stochastic Gradient Descent
  - [An overview of gradient descent optimization algorithms](https://arxiv.org/abs/1609.04747)

- Adam Optimizer
  - [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)


## Evaluation Metrics & Frameworks

- Inception Score and FrÃ©chet Inception Distance (FID)
  - [A Note on the Inception Score](https://arxiv.org/abs/1801.01973)

- BLEU Score and ROUGE Score
  - [BLEU: a Method for Automatic Evaluation of Machine Translation](https://www.aclweb.org/anthology/P02-1040.pdf)

- TruLens
  - [TruLens Documentation](https://www.trulens.org/trulens/getting_started/)
 
- RAGAS
  - [RAGAS Documentation](https://docs.ragas.io/en/latest/getstarted/index.html)


## Advanced Techniques

- Few-Shot Learning
  - [Matching Networks for One Shot Learning](https://arxiv.org/abs/1606.04080)

- Transfer Learning
  - [A Survey on Transfer Learning](https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf)


## Ethical Considerations

- Bias in Generative Models
  - [The Ethics of AI Ethics: An Evaluation of Guidelines](https://link.springer.com/article/10.1007/s11023-020-09517-8)

- Deepfakes and Misinformation
  - [The Creation and Detection of Deepfakes: A Survey](https://arxiv.org/abs/2004.11138)


## Interpretability and Explainability

- Saliency Maps and Activation Maximization
  - [Methods for Interpreting and Understanding Deep Neural Networks](https://arxiv.org/abs/1706.07979)


## Applications

- Text Generation
  - [The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751)

- Image Synthesis
  - [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)


## Challenges and Future Directions

- Controllable Generation
  - [Plug and Play Language Models: A Simple Approach to Controlled Text Generation](https://arxiv.org/abs/1912.02164)
  - 

- Energy Efficiency in Generation
  - [Green AI](https://arxiv.org/abs/1907.10597)
  - 
